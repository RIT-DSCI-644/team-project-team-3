{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of Saturday March 23:\n",
    "\n",
    "To run this program you need the three datasets and the stopwords file in the same directory as this program.\n",
    "\n",
    "The program does the following:\n",
    "Puts the three tweet datasets into dataframes.\n",
    "Performs sentiment analysis on the tweets using the nltk.vader tool.   This is a lexicon based sentiment analysis trained using social media sources, so we assume it is somewhat applicable.  The analysis is added to the dataframes in two forms, the overall score from -1 to 1 showing magnitude of sentiment, as well as an integer score of -1,0,1 (meaning negative positive neutral) showing only direction of sentiment.  Called Vader_Score and Trinary_Score.\n",
    "\n",
    "A shortcoming of this analysis as is is that any new slang terms or created words or hashtags likely won't be interpretted by the classifier so they'll be simply counted as neutral.  Might miss SOME of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import math\n",
    "#import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/chris/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Downloads the lexicon used for sentiment anlysis.  Can comment out after run once.\n",
    "nltk.downloader.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the datasets and turn into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump=pd.read_csv('trump_raw.csv')\n",
    "clinton=pd.read_csv('clinton_raw.csv')\n",
    "congress=pd.read_csv('congress_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords for basic text cleaning for wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "file2=open('stopwords.csv', encoding='utf8')   #file of stopwords from another project...may need to make this file bigger.\n",
    "for stopword in file2.read().split():\n",
    "    stopword = stopword.replace('\"','')\n",
    "    stopwords.append(stopword)\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Wordcloud Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Setting up wordcloud creation.   Takes a list of text entries that we create later.\n",
    "###Second argument is size of the cloud you want returned.  default is top 20 words\n",
    "def make_cloud(words, num=20):\n",
    "    wordcount={}\n",
    "    for line in words:\n",
    "        for word in line.split():\n",
    "            if word in stopwords:\n",
    "                pass\n",
    "        \n",
    "            elif word not in wordcount:\n",
    "                wordcount[word] = 1\n",
    "            else:\n",
    "                wordcount[word] += 1\n",
    "    \n",
    "    d = collections.Counter(wordcount)\n",
    "        \n",
    "    for word, count in d.most_common(num):\n",
    "        print(word, \": \", count)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab All of the text from the tweets from a given DataFrame.  For use with wordcloud generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_text(df):\n",
    "    cw =[]\n",
    "    df = df[\"text\"]   #Grab just the fourth column\n",
    "        \n",
    "    for x in df.index:    #Iterate over the valid indicies. Need this since congresslib/con are partials. \n",
    "        temp=str(df[x])\n",
    "        temp.strip()                  ##Cleans up the text of junk characters\n",
    "        temp=temp.replace('.','')  #stripping out common punctuation so words ending with commas and periods don't count as two different words.\n",
    "        temp=temp.replace(',','')\n",
    "        temp=temp.replace('“','')\n",
    "        temp=temp.replace('”','')\n",
    "        temp=temp.replace('&amp','')\n",
    "        temp=temp.replace(';','')\n",
    "        temp=temp.replace('-',' ')\n",
    "        temp=temp.lower()\n",
    "        cw.append(temp)\n",
    "    return cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thank :  749\n",
      "great :  663\n",
      "@realdonaldtrump :  534\n",
      "hillary :  467\n",
      "#trump2016 :  453\n",
      "trump :  441\n",
      "#makeamericagreatagain :  295\n",
      "new :  288\n",
      "people :  274\n",
      "america :  274\n",
      "clinton :  258\n",
      "crooked :  224\n",
      "cruz :  200\n",
      "big :  185\n",
      "you! :  185\n",
      "join :  165\n",
      "poll :  164\n",
      "one :  160\n",
      "@cnn :  158\n",
      "going :  149\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###Example of word cloud.  Not sure if we'll use this.  We may use its helpr functions if we build our own \n",
    "###classifier...\n",
    "\n",
    "\n",
    "make_cloud(grab_text(trump))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis Stuff follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###The analyzer.  returns a number between [-1,1] with -1 being very negative and 1 being very positive.\n",
    "###Use the compound output as the overall sentiment. (it's some kind of combination of all three attributes)\n",
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Gives a Trinary Poisitive/Negative/Neutral answer.  Will be useful for strict counts of positive/negative/neutral.\n",
    "\n",
    "def vader_polarity(text):\n",
    "    \"\"\" Transform the output to a binary 0/1 result \"\"\"\n",
    "    score = vader.polarity_scores(text)\n",
    "    if score['pos'] > score['neg']:\n",
    "        x=1\n",
    "    elif score['pos'] < score['neg']:\n",
    "        x=-1\n",
    "    else:\n",
    "        x=0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would be nice if @jmartNYT learned how to read the polls before writing his next story. Probably done on purpose, but not good reporting!\n",
      "{'neg': 0.125, 'neu': 0.806, 'pos': 0.07, 'compound': -0.3614}\n",
      "-1\n",
      "\n",
      ".@RobertGBeckel Please thank your brother for his nice words on television. Seems like a great guy and character! @CNN\n",
      "{'neg': 0.0, 'neu': 0.473, 'pos': 0.527, 'compound': 0.9259}\n",
      "1\n",
      "\n",
      "\"@essygalloway: @realDonaldTrump @nbcsnl @Sia  I can't wait to watch snl tomorrow.\" A really big show!\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "##Example of the sentiment analyzer and the trinary classifications\n",
    "##Shows a tweet, the vader nltk.vader analysis, and the trinary classification.\n",
    "\n",
    "x1=trump['text'][0]\n",
    "print(x1)\n",
    "print(vader.polarity_scores(x1))\n",
    "print(str(vader_polarity(x1))+\"\\n\")\n",
    "x2=trump['text'][5]\n",
    "print(x2)\n",
    "print(vader.polarity_scores(x2))\n",
    "print(str(vader_polarity(x2))+\"\\n\")\n",
    "x3=trump['text'][4]\n",
    "print(x3)\n",
    "print(vader.polarity_scores(x3))\n",
    "print(vader_polarity(x3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output from vader gives 4 numbers.  we should use the compound number.  It is calculated using some sort of squishing formula behind the scenes... it's exact function is not important to this analysis and the number should work fine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for analyzing sentiment of all tweets and appending to datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_data_sentiment(df):\n",
    "    Vader_Score = []\n",
    "    Trinary_Score = []\n",
    "    df = df[\"text\"]   #Grab just the fourth column\n",
    "        \n",
    "    for x in df.index:    #Iterate over the valid indicies. Need this since congresslib/con are partials. \n",
    "        temp=str(df[x])\n",
    "        vad_score=vader.polarity_scores(temp)['compound']\n",
    "        trin_score=vader_polarity(temp)\n",
    "        \n",
    "        Vader_Score.append(vad_score)\n",
    "        Trinary_Score.append(trin_score)\n",
    "    return Vader_Score, Trinary_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,z=grab_data_sentiment(trump)\n",
    "trump.insert(0,'Vader_Score',y)\n",
    "trump.insert(0,'Trinary_Score',z)\n",
    "\n",
    "y,z=grab_data_sentiment(clinton)\n",
    "clinton.insert(0,'Vader_Score',y)\n",
    "clinton.insert(0,'Trinary_Score',z)\n",
    "\n",
    "##This one takes a while, large dataset...\n",
    "y,z=grab_data_sentiment(congress)\n",
    "congress.insert(0,'Vader_Score',y)\n",
    "congress.insert(0,'Trinary_Score',z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the dataframe with the sentiment scores inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trinary_Score</th>\n",
       "      <th>Vader_Score</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>AffectCount</th>\n",
       "      <th>MoralCount</th>\n",
       "      <th>shared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.3614</td>\n",
       "      <td>11/7/2015 0:07</td>\n",
       "      <td>1824</td>\n",
       "      <td>796</td>\n",
       "      <td>Would be nice if @jmartNYT learned how to read...</td>\n",
       "      <td>11/7/2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11/7/2015 0:08</td>\n",
       "      <td>2285</td>\n",
       "      <td>4029</td>\n",
       "      <td>\"@nbcsnl: One more day! Donald Trump hosts #SN...</td>\n",
       "      <td>11/7/2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.6616</td>\n",
       "      <td>11/7/2015 3:23</td>\n",
       "      <td>2333</td>\n",
       "      <td>986</td>\n",
       "      <td>\"@Bubbachitchat1: THIS IS WHY THE POLLS ARE WR...</td>\n",
       "      <td>11/7/2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.7712</td>\n",
       "      <td>11/7/2015 5:20</td>\n",
       "      <td>3012</td>\n",
       "      <td>1215</td>\n",
       "      <td>One of the dumbest political pundits on televi...</td>\n",
       "      <td>11/7/2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11/7/2015 5:23</td>\n",
       "      <td>1892</td>\n",
       "      <td>703</td>\n",
       "      <td>\"@essygalloway: @realDonaldTrump @nbcsnl @Sia ...</td>\n",
       "      <td>11/7/2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trinary_Score  Vader_Score      created_at  favorite_count  retweet_count  \\\n",
       "0             -1      -0.3614  11/7/2015 0:07            1824            796   \n",
       "1              0       0.0000  11/7/2015 0:08            2285           4029   \n",
       "2             -1      -0.6616  11/7/2015 3:23            2333            986   \n",
       "3             -1      -0.7712  11/7/2015 5:20            3012           1215   \n",
       "4              0       0.0000  11/7/2015 5:23            1892            703   \n",
       "\n",
       "                                                text       time  AffectCount  \\\n",
       "0  Would be nice if @jmartNYT learned how to read...  11/7/2015            1   \n",
       "1  \"@nbcsnl: One more day! Donald Trump hosts #SN...  11/7/2015            0   \n",
       "2  \"@Bubbachitchat1: THIS IS WHY THE POLLS ARE WR...  11/7/2015            0   \n",
       "3  One of the dumbest political pundits on televi...  11/7/2015            1   \n",
       "4  \"@essygalloway: @realDonaldTrump @nbcsnl @Sia ...  11/7/2015            0   \n",
       "\n",
       "   MoralCount  shared  \n",
       "0           0       1  \n",
       "1           0       0  \n",
       "2           0       1  \n",
       "3           1       1  \n",
       "4           0       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create DFs for separated congress for basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(congress['dw_score'])  ##negatives were parsing as strings\n",
    "lib_filter=congress['dw_score']<0\n",
    "con_filter=congress['dw_score']>0\n",
    "congress_lib=pd.DataFrame(congress[lib_filter])  ##Creating copies to get rid of indexing issues.\n",
    "congress_con=pd.DataFrame(congress[con_filter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trinary_Score</th>\n",
       "      <th>Vader_Score</th>\n",
       "      <th>text</th>\n",
       "      <th>elite</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>media</th>\n",
       "      <th>gender</th>\n",
       "      <th>dw_extr</th>\n",
       "      <th>dwextr_rs</th>\n",
       "      <th>dw_score</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>Today is the 1 yr anniversary of the #STEMEduc...</td>\n",
       "      <td>Adams</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.462</td>\n",
       "      <td>-0.462</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>71</td>\n",
       "      <td>8386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.6597</td>\n",
       "      <td>Find a Breast Cancer screening provider near y...</td>\n",
       "      <td>Adams</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.462</td>\n",
       "      <td>-0.462</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>71</td>\n",
       "      <td>8386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>October is #BreastCancerAwarenessMonth. Find e...</td>\n",
       "      <td>Adams</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.462</td>\n",
       "      <td>-0.462</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>71</td>\n",
       "      <td>8386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>My office is now accepting applications for no...</td>\n",
       "      <td>Adams</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.462</td>\n",
       "      <td>-0.462</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>71</td>\n",
       "      <td>8386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3262</td>\n",
       "      <td>Please stay safe this week NC. For more inform...</td>\n",
       "      <td>Adams</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.462</td>\n",
       "      <td>-0.462</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>71</td>\n",
       "      <td>8386.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Trinary_Score  Vader_Score  \\\n",
       "41              1       0.4019   \n",
       "42             -1      -0.6597   \n",
       "43              0       0.0000   \n",
       "44              1       0.3818   \n",
       "45              1       0.3262   \n",
       "\n",
       "                                                 text  elite  retweet_count  \\\n",
       "41  Today is the 1 yr anniversary of the #STEMEduc...  Adams              3   \n",
       "42  Find a Breast Cancer screening provider near y...  Adams              0   \n",
       "43  October is #BreastCancerAwarenessMonth. Find e...  Adams              0   \n",
       "44  My office is now accepting applications for no...  Adams              0   \n",
       "45  Please stay safe this week NC. For more inform...  Adams              2   \n",
       "\n",
       "    media  gender  dw_extr  dwextr_rs  dw_score  race  age  followers  \n",
       "41   -0.5    -0.5    0.462      0.462    -0.462  -0.5   71     8386.0  \n",
       "42    0.5    -0.5    0.462      0.462    -0.462  -0.5   71     8386.0  \n",
       "43   -0.5    -0.5    0.462      0.462    -0.462  -0.5   71     8386.0  \n",
       "44   -0.5    -0.5    0.462      0.462    -0.462  -0.5   71     8386.0  \n",
       "45   -0.5    -0.5    0.462      0.462    -0.462  -0.5   71     8386.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congress_lib.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
